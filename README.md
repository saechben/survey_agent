# Survey Agent

Streamlit-powered survey assistant that blends traditional questionnaires with AI-driven guidance, speech tooling, and lightweight analytics. Respondents can move through a curated set of questions, hear each prompt read aloud, capture answers by typing or speaking, and receive contextual follow-up prompts generated by an OpenAI model. Once finished, the session is summarised, stored, and can be explored with an embedded analysis agent.

## Key Features
- Guided survey UI with progress tracking and restart controls.
- Automatic text-to-speech playback, microphone capture, and Whisper transcription.
- LLM-generated follow-up questions that surface when free-text answers need clarification.
- Persistent JSON storage for completed surveys, ready for downstream processing.
- Analysis agent that answers natural-language questions about captured responses.
- Simple text-file survey format that supports both free-text and categorical questions.

## Functionality
- Conversational Flow & Guardrails: Orchestrates a question-by-question journey with clear progress, previous/next controls, and finish gating that ensures required follow-ups are captured before moving on.
- Voice-First UX: Autoplay narration, typewriter-synced text, and background audio prefetching keep the experience silky-smooth; one-click mic capture pairs Whisper transcription with GPT‚Äë4o‚Äëmini TTS for hands-free answering.
- Smart Follow-Ups: A compact PydanticAI agent reads free-text answers and decides when to probe or skip, providing concise follow-up prompts (with graceful fallbacks if the model is unavailable).
- Lightweight Persistence: Stores responses, follow-up prompts, and follow-up answers in a tidy JSON ledger‚Äîeasy to inspect today, trivial to swap for a real database tomorrow.
- Inline Analytics: An embedded analysis agent answers natural-language questions grounded in your recorded survey snapshot, streaming approachable, bullet-point insights with live status updates.
- Simple Authoring & Config: Author surveys as readable `.txt` files (add `|` options for multiple choice) and tune behaviour via environment variables for models, speech voices, formats, and file paths.

## Quick Start
```bash
# Python 3.13+ and Poetry are required
poetry install

# Provide the required environment variables (see below), then launch Streamlit
poetry run streamlit run app/main.py
```

The UI opens in your browser at `http://localhost:8501`.

## Configuration
The app reads configuration from environment variables or a local `.env` file. At minimum, supply an OpenAI API key and target model:

```bash
LLM_API_KEY=sk-...
LLM_MODEL=gpt-4o-mini

# Optional overrides shown with their defaults
SURVEY_FILE_PATH=app/data/strategic_outcomes_survey.txt
SURVEY_RESULTS_PATH=app/data/survey_results.txt
SPEECH_PROVIDER=openai
SPEECH_STT_MODEL=whisper-1
SPEECH_TTS_MODEL=gpt-4o-mini-tts
SPEECH_TTS_VOICE=nova
SPEECH_TTS_FORMAT=mp3
SPEECH_LANGUAGE=en
```

The survey loader expects a plain-text file where each line is a question. Add `|` followed by comma-separated options to mark a question as multiple choice. Example (`app/data/sample_survey.txt`):

```
What is your preferred mode of contact? | Email, Phone, SMS
What improvements would you like to see?
```

Survey responses and follow-up metadata are stored in `SURVEY_RESULTS_PATH` as JSON.

## Using the App
- Press **Start survey** to begin. Each question displays a progress indicator and optional speech toggle.
- Use the üéôÔ∏è toggle to enable automatic text-to-speech playback for questions (audio is prefetched while the survey loads).
- For free-text questions, record an answer with the microphone button or type directly. The system transcribes speech using Whisper and lets you edit before saving.
- When a free-text response needs elaboration, an OpenAI-powered agent drafts a follow-up prompt. Answer it to proceed or skip if the agent judged no follow-up is required.
- After completing all questions, review the response summary and optionally ask the analysis agent for insights like ‚ÄúWhat themes did respondents mention most?‚Äù.

## Project Layout
- `app/main.py` ‚Äì Streamlit entry point.
- `app/UI/` ‚Äì Front-end components, session state, speech controls, and navigation.
- `app/services/` ‚Äì Integrations for survey loading, OpenAI speech/LLM calls, follow-up agent, and persistence.
- `app/models/` ‚Äì Pydantic models for surveys and analysis snapshots.
- `app/API/` ‚Äì Data providers that assemble survey context for the analysis agent.
- `app/data/` ‚Äì Example surveys and the default results store.

## Development
- Run tests: `poetry run pytest`
- Formatters/linters are not enforced yet; keep contributions PEP 8 friendly.
- A `Dockerfile` is included if you prefer containerised execution.

## Next Steps
Ideas for extension include wiring charts from `app/services/charts.py` into the UI, swapping the storage layer for a real database, or enabling multi-survey management.
