# Survey Agent

Streamlit-powered survey assistant that blends traditional questionnaires with AI-driven guidance, speech tooling, and lightweight analytics. Respondents can move through a curated set of questions, hear each prompt read aloud, capture answers by typing or speaking, and receive contextual follow-up prompts generated by an OpenAI model. Once finished, the session is summarised, stored, and can be explored with an embedded analysis agent.

## Key Features
- Guided survey UI with progress tracking and restart controls.
- Automatic text-to-speech playback, microphone capture, and Whisper transcription.
- LLM-generated follow-up questions that surface when free-text answers need clarification.
- Persistent JSON storage for completed surveys, ready for downstream processing.
- Analysis agent that answers natural-language questions about captured responses.
- Simple text-file survey format that supports both free-text and categorical questions.

## Quick Start
```bash
# Python 3.13+ and Poetry are required
poetry install

# Provide the required environment variables (see below), then launch Streamlit
poetry run streamlit run app/main.py
```

The UI opens in your browser at `http://localhost:8501`.

## Configuration
The app reads configuration from environment variables or a local `.env` file. At minimum, supply an OpenAI API key and target model:

```bash
LLM_API_KEY=sk-...
LLM_MODEL=gpt-4o-mini

# Optional overrides shown with their defaults
SURVEY_FILE_PATH=app/data/real_survey.txt
SURVEY_RESULTS_PATH=app/data/survey_results.txt
SPEECH_PROVIDER=openai
SPEECH_STT_MODEL=whisper-1
SPEECH_TTS_MODEL=gpt-4o-mini-tts
SPEECH_TTS_VOICE=nova
SPEECH_TTS_FORMAT=mp3
SPEECH_LANGUAGE=en
```

The survey loader expects a plain-text file where each line is a question. Add `|` followed by comma-separated options to mark a question as multiple choice. Example (`app/data/sample_survey.txt`):

```
What is your preferred mode of contact? | Email, Phone, SMS
What improvements would you like to see?
```

Survey responses and follow-up metadata are stored in `SURVEY_RESULTS_PATH` as JSON.

## Using the App
- Press **Start survey** to begin. Each question displays a progress indicator and optional speech toggle.
- Use the üéôÔ∏è toggle to enable automatic text-to-speech playback for questions (audio is prefetched while the survey loads).
- For free-text questions, record an answer with the microphone button or type directly. The system transcribes speech using Whisper and lets you edit before saving.
- When a free-text response needs elaboration, an OpenAI-powered agent drafts a follow-up prompt. Answer it to proceed or skip if the agent judged no follow-up is required.
- After completing all questions, review the response summary and optionally ask the analysis agent for insights like ‚ÄúWhat themes did respondents mention most?‚Äù.

## Project Layout
- `app/main.py` ‚Äì Streamlit entry point.
- `app/UI/` ‚Äì Front-end components, session state, speech controls, and navigation.
- `app/services/` ‚Äì Integrations for survey loading, OpenAI speech/LLM calls, follow-up agent, and persistence.
- `app/models/` ‚Äì Pydantic models for surveys and analysis snapshots.
- `app/API/` ‚Äì Data providers that assemble survey context for the analysis agent.
- `app/data/` ‚Äì Example surveys and the default results store.

## Development
- Run tests: `poetry run pytest`
- Formatters/linters are not enforced yet; keep contributions PEP 8 friendly.
- A `Dockerfile` is included if you prefer containerised execution.

## Next Steps
Ideas for extension include wiring charts from `app/services/charts.py` into the UI, swapping the storage layer for a real database, or enabling multi-survey management.
